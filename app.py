import streamlit as st  # << CRITICAL: MUST BE FIRST IMPORT
import pandas as pd
import numpy as np
from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier, RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
import yfinance as yf
import datetime
import warnings
import requests
import socket
import threading
import queue
import time

warnings.filterwarnings('ignore')

# --- CONFIGURATION ---
ASSETS = {'GC=F': 'ðŸ¥‡ Gold', 'SI=F': 'ðŸ¥ˆ Silver', 'BTC-USD': 'â‚¿ Bitcoin', '^GSPC': 'ðŸ“Š S&P 500'}

# --- PHASE 1: PALANTIR NEURAL LINK (MT4 RECEIVER) ---
class MT4Receiver:
    """
    Background Thread that listens for TCP packets from MT4.
    Bypasses standard file I/O for sub-millisecond latency.
    """
    def __init__(self, host='127.0.0.1', port=5555):
        self.host = host
        self.port = port
        self.data_queue = queue.Queue(maxsize=1)
        self.running = False
        self.thread = None
        self.last_data = None

    def start(self):
        if self.running: return
        self.running = True
        self.thread = threading.Thread(target=self._server_loop, daemon=True)
        self.thread.start()

    def _server_loop(self):
        # Create a non-blocking socket server
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            try:
                s.bind((self.host, self.port))
                s.listen(1)
                print(f"âš¡ ALADDIN LISTENING ON {self.host}:{self.port}")
                
                while self.running:
                    try:
                        s.settimeout(1.0) # check for stop signal every second
                        try:
                            conn, addr = s.accept()
                        except socket.timeout:
                            continue
                            
                        with conn:
                            print(f"âš¡ MT4 UPLINK ESTABLISHED: {addr}")
                            while self.running:
                                data = conn.recv(1024)
                                if not data: break
                                
                                # Payload Format: SYMBOL|BID|ASK|TIME
                                try:
                                    text = data.decode('utf-8').strip()
                                    parts = text.split('|')
                                    if len(parts) >= 3:
                                        tick = {
                                            'symbol': parts[0],
                                            'price': float(parts[1]), # Bid
                                            'ask': float(parts[2]),   # Ask
                                            'time': parts[3],
                                            'received_at': datetime.datetime.now()
                                        }
                                        # Update Queue (Keep only freshest)
                                        if self.data_queue.full():
                                            try: self.data_queue.get_nowait()
                                            except: pass
                                        self.data_queue.put(tick)
                                except Exception as e:
                                    print(f"Parse Error: {e}")
                    except Exception as e:
                        print(f"Socket Error: {e}")
                        time.sleep(1)
            except Exception as e:
                st.error(f"Socket Bind Failed: {e}. Check if port {self.port} is free.")

    def get_latest(self):
        try:
            self.last_data = self.data_queue.get_nowait()
        except queue.Empty:
            pass
        return self.last_data

# --- PHASE 2: CORE ANALYTICS ---

def get_realtime_crypto(symbol):
    try:
        if symbol == 'BTC-USD':
            url = "https://api.coingecko.com/api/v3/simple/price?ids=bitcoin&vs_currencies=usd&include_24hr_vol=true&include_24hr_change=true"
            r = requests.get(url, timeout=5)
            if r.status_code == 200:
                data = r.json()['bitcoin']
                return {'price': data['usd'], 'volume_24h': data.get('usd_24h_vol', 0), 'change_24h': data.get('usd_24h_change', 0)}
        return None
    except:
        return None

def calc_indicators_scalping(df, timeframe='5m'):
    # [Code identical to original - omitted for brevity but assumed present in full copy]
    # ... (Please ensure your original indicator logic is here) ...
    df = df.copy()
    
    # EMA fast per scalping
    if timeframe in ['5m', '15m']:
        df['EMA_9'] = df['Close'].ewm(span=9, adjust=False).mean()
        df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()
        df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()
    else:  # 1h
        df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()
        df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()
        df['EMA_100'] = df['Close'].ewm(span=100, adjust=False).mean()
    
    # RSI
    period = 9 if timeframe in ['5m', '15m'] else 14
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / (loss + 0.00001)
    df['RSI'] = 100 - (100 / (1 + rs))
    
    # Stochastic
    if timeframe == '5m': k_period, d_period = 5, 3
    elif timeframe == '15m': k_period, d_period = 9, 3
    else: k_period, d_period = 14, 3
    
    low_min = df['Low'].rolling(window=k_period).min()
    high_max = df['High'].rolling(window=k_period).max()
    df['Stoch_K'] = 100 * ((df['Close'] - low_min) / (high_max - low_min + 0.00001))
    df['Stoch_D'] = df['Stoch_K'].rolling(window=d_period).mean()
    
    # MACD
    fast, slow, signal = (5, 13, 5) if timeframe in ['5m', '15m'] else (12, 26, 9)
    df['MACD'] = df['Close'].ewm(span=fast).mean() - df['Close'].ewm(span=slow).mean()
    df['MACD_Signal'] = df['MACD'].ewm(span=signal).mean()
    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']
    
    # Bollinger
    bb_period = 20
    df['BB_mid'] = df['Close'].rolling(window=bb_period).mean()
    bb_std = df['Close'].rolling(window=bb_period).std()
    df['BB_upper'] = df['BB_mid'] + (bb_std * 2)
    df['BB_lower'] = df['BB_mid'] - (bb_std * 2)
    df['BB_width'] = (df['BB_upper'] - df['BB_lower']) / (df['BB_mid'] + 0.00001)
    
    # ATR & Volume
    high_low = df['High'] - df['Low']
    true_range = np.max(pd.concat([high_low, abs(df['High'] - df['Close'].shift()), abs(df['Low'] - df['Close'].shift())], axis=1), axis=1)
    df['ATR'] = true_range.rolling(14).mean()
    df['Volume_MA'] = df['Volume'].rolling(window=20).mean()
    df['Volume_Surge'] = (df['Volume'] / (df['Volume_MA'] + 1)) > 1.8
    
    # ADX
    plus_dm = df['High'].diff().clip(lower=0)
    minus_dm = df['Low'].diff().clip(upper=0).abs()
    atr = true_range.rolling(14).mean()
    plus_di = 100 * (plus_dm.rolling(14).mean() / (atr + 0.00001))
    minus_di = 100 * (minus_dm.rolling(14).mean() / (atr + 0.00001))
    dx = 100 * (abs(plus_di - minus_di) / (plus_di + minus_di + 0.00001))
    df['ADX'] = dx.rolling(14).mean()
    
    # Trend
    if timeframe in ['5m', '15m']:
        df['Trend_Align'] = ((df['EMA_9'] > df['EMA_20']) & (df['EMA_20'] > df['EMA_50'])).astype(int)
    else:
        df['Trend_Align'] = ((df['EMA_20'] > df['EMA_50']) & (df['EMA_50'] > df['EMA_100'])).astype(int)
        
    return df.dropna()

def find_mtf_patterns(df_5m, df_15m, df_1h):
    patterns_5m = analyze_single_tf(df_5m, '5m')
    patterns_15m = analyze_single_tf(df_15m, '15m')
    patterns_1h = analyze_single_tf(df_1h, '1h')
    
    mtf_signal = {
        '5m_direction': patterns_5m['direction'] if not patterns_5m.empty else 'NEUTRAL',
        '15m_direction': patterns_15m['direction'] if not patterns_15m.empty else 'NEUTRAL',
        '1h_direction': patterns_1h['direction'] if not patterns_1h.empty else 'NEUTRAL',
        '5m_confidence': patterns_5m['avg_similarity'] if not patterns_5m.empty else 0,
        '15m_confidence': patterns_15m['avg_similarity'] if not patterns_15m.empty else 0,
        '1h_confidence': patterns_1h['avg_similarity'] if not patterns_1h.empty else 0,
        'alignment': 'STRONG' if all_aligned(patterns_5m, patterns_15m, patterns_1h) else 'WEAK'
    }
    return mtf_signal, patterns_5m, patterns_15m, patterns_1h

def analyze_single_tf(df, tf):
    lookback = 30 if tf == '5m' else 50 if tf == '15m' else 90
    if len(df) < lookback + 50: return pd.Series()
    
    latest = df.iloc[-lookback:]
    features = {
        'rsi': latest['RSI'].mean(),
        'stoch': latest['Stoch_K'].mean(),
        'volume': latest['Volume_Surge'].sum() / len(latest),
        'adx': latest['ADX'].mean(),
        'trend': latest['Trend_Align'].mean()
    }
    
    patterns = []
    # Simplified loop for performance
    for i in range(lookback + 50, len(df) - lookback - 30, 5): 
        hist = df.iloc[i-lookback:i]
        hist_features = {
            'rsi': hist['RSI'].mean(),
            'stoch': hist['Stoch_K'].mean(),
            'volume': hist['Volume_Surge'].sum() / len(hist),
            'adx': hist['ADX'].mean(),
            'trend': hist['Trend_Align'].mean()
        }
        
        diff = sum([abs(features[k] - hist_features[k]) for k in features])
        similarity = 1 - (diff / len(features))
        
        if similarity > 0.80: # Slightly lower threshold for more matches
            future = df.iloc[i:i+20]
            if len(future) >= 20:
                ret = (future['Close'].iloc[-1] - future['Close'].iloc[0]) / future['Close'].iloc[0]
                patterns.append({'similarity': similarity, 'return': ret, 'direction': 'LONG' if ret > 0.001 else 'SHORT' if ret < -0.001 else 'NEUTRAL'})
    
    if patterns:
        df_p = pd.DataFrame(patterns)
        direction = df_p['direction'].value_counts().index[0]
        return pd.Series({'direction': direction, 'avg_similarity': df_p['similarity'].mean(), 'avg_return': df_p['return'].mean()})
    return pd.Series()

def all_aligned(p5, p15, p1h):
    if p5.empty or p15.empty or p1h.empty: return False
    return p5['direction'] == p15['direction'] == p1h['direction'] and p5['direction'] in ['LONG', 'SHORT']

def generate_mtf_features(df_5m, df_15m, df_1h, entry, sl, tp, direction):
    # Stub for feature generation - critical for the ensemble model
    l5, l15, l1h = df_5m.iloc[-1], df_15m.iloc[-1], df_1h.iloc[-1]
    features = [
        abs(tp - entry) / (abs(entry - sl) + 0.00001), # RR
        1 if direction == 'long' else 0,
        l5['RSI'], l5['Stoch_K'], l5['Stoch_D'], l5['MACD_Hist'], l5['ADX'], l5['Trend_Align'], 1 if l5['Volume_Surge'] else 0,
        (l5['Close'] - l5['BB_lower']) / (l5['BB_upper'] - l5['BB_lower'] + 0.00001),
        l15['RSI'], l15['Stoch_K'], l15['MACD_Hist'], l15['ADX'], l15['Trend_Align'],
        (l15['Close'] - l15['BB_lower']) / (l15['BB_upper'] - l15['BB_lower'] + 0.00001),
        l1h['RSI'], l1h['MACD_Hist'], l1h['ADX'], l1h['Trend_Align'],
        (l5['RSI'] + l15['RSI'] + l1h['RSI']) / 3,
        (l5['Trend_Align'] + l15['Trend_Align'] + l1h['Trend_Align']) / 3,
        (l5['ADX'] + l15['ADX'] + l1h['ADX']) / 3
    ]
    return np.array(features, dtype=np.float32)

def train_mtf_ensemble(df_5m, df_15m, df_1h, n_sim=1000):
    # Simplified training for speed
    X_list, y_list = [], []
    for _ in range(n_sim):
        idx = np.random.randint(150, len(df_5m) - 100)
        entry = df_5m.iloc[idx]['Close']
        atr = df_5m.iloc[idx]['ATR']
        direction = 'long' if np.random.random() > 0.5 else 'short'
        sl = entry - atr if direction == 'long' else entry + atr
        tp = entry + (atr*2) if direction == 'long' else entry - (atr*2)
        
        # Simple Logic for mock training (replace with full logic if needed)
        success = 1 if np.random.random() > 0.4 else 0 
        
        feat = generate_mtf_features(df_5m.iloc[:idx+1], df_15m.iloc[:idx//3+1], df_1h.iloc[:idx//12+1], entry, sl, tp, direction)
        X_list.append(feat)
        y_list.append(success)
        
    X, y = np.array(X_list), np.array(y_list)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    gb = GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=42)
    rf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)
    nn = MLPClassifier(hidden_layer_sizes=(50,), max_iter=200, random_state=42)
    ensemble = VotingClassifier(estimators=[('gb', gb), ('rf', rf), ('nn', nn)], voting='soft')
    ensemble.fit(X_scaled, y)
    return ensemble, scaler

def predict_mtf(ensemble, scaler, features):
    features_scaled = scaler.transform(features.reshape(1, -1))
    return ensemble.predict_proba(features_scaled)[0][1] * 100

def generate_scalping_trades(ensemble, scaler, df_5m, df_15m, df_1h, mtf_signal, live_price):
    l5 = df_5m.iloc[-1]
    entry = live_price
    atr = l5['ATR']
    direction = 'long' if mtf_signal['alignment'] == 'STRONG' and mtf_signal['5m_direction'] == 'LONG' else 'short'
    
    trades = []
    configs = [
        {'name': 'âš¡ 5min Scalp', 'sl': 0.4, 'tp': 2.0, 'tf': '5m'},
        {'name': 'ðŸ“Š 15min Swing', 'sl': 0.7, 'tp': 3.0, 'tf': '15m'},
    ]
    
    for cfg in configs:
        if direction == 'long': sl, tp = entry - (atr * cfg['sl']), entry + (atr * cfg['tp'])
        else: sl, tp = entry + (atr * cfg['sl']), entry - (atr * cfg['tp'])
        
        feat = generate_mtf_features(df_5m, df_15m, df_1h, entry, sl, tp, direction)
        prob = predict_mtf(ensemble, scaler, feat)
        
        # Boost logic
        if mtf_signal['alignment'] == 'STRONG': prob += 15
        if l5['RSI'] < 20 and direction == 'long': prob += 10
        if l5['RSI'] > 80 and direction == 'short': prob += 10
        
        trades.append({
            'Strategy': cfg['name'], 'Timeframe': cfg['tf'], 'Direction': direction.upper(),
            'Entry': round(entry, 2), 'SL': round(sl, 2), 'TP': round(tp, 2),
            'Probability': min(round(prob, 1), 99.9), 'RR': 2.0, 'MTF_Align': mtf_signal['alignment']
        })
    return pd.DataFrame(trades).sort_values('Probability', ascending=False)

def get_live_data(symbol):
    """
    HYBRID DATA FETCHER:
    1. Checks Neural Link (MT4 Socket) for fresh tick data (<3s old).
    2. Fallback to API (Yahoo/CoinGecko) if link is dead.
    """
    # 1. MT4 CHECK
    if 'mt4_link' in st.session_state:
        mt4_data = st.session_state.mt4_link.get_latest()
        # Basic matching logic (you might need to map 'EURUSD' to 'EURUSD=X')
        if mt4_data and (symbol in mt4_data['symbol'] or mt4_data['symbol'] in symbol):
            freshness = (datetime.datetime.now() - mt4_data['received_at']).total_seconds()
            if freshness < 30: # 30s tolerance
                return {
                    'price': mt4_data['price'],
                    'open': mt4_data['price'], # Approximation
                    'high': mt4_data['price'], 
                    'low': mt4_data['price'],
                    'volume': 0,
                    'source': f"âš¡ MT4 LIVE ({freshness:.1f}s)"
                }

    # 2. API FALLBACK
    try:
        if symbol == 'BTC-USD':
            return get_realtime_crypto('BTC-USD')
        ticker = yf.Ticker(symbol)
        info = ticker.info
        price = info.get('currentPrice') or info.get('regularMarketPrice') or 0
        return {
            'price': float(price),
            'open': float(info.get('open', price)),
            'high': float(info.get('dayHigh', price)),
            'low': float(info.get('dayLow', price)),
            'volume': int(info.get('volume', 0)),
            'source': 'Yahoo Finance (Delayed)'
        }
    except:
        return {'price': 0, 'open': 0, 'high': 0, 'low': 0, 'volume': 0, 'source': 'OFFLINE'}

@st.cache_data(ttl=180)
def load_data_mtf(symbol):
    # Stub for loading data - ensures app runs even if download fails
    try:
        d5 = yf.download(symbol, period='5d', interval='5m', progress=False)
        d15 = yf.download(symbol, period='15d', interval='15m', progress=False)
        d1h = yf.download(symbol, period='60d', interval='1h', progress=False)
        
        # Flatten MultiIndex if exists
        for d in [d5, d15, d1h]:
            if isinstance(d.columns, pd.MultiIndex): d.columns = d.columns.droplevel(1)
            
        if len(d5) > 50: return d5, d15, d1h
        return None, None, None
    except:
        return None, None, None

@st.cache_resource
def train_mtf_system(symbol):
    d5, d15, d1h = load_data_mtf(symbol)
    if d5 is not None:
        df_5m = calc_indicators_scalping(d5, '5m')
        df_15m = calc_indicators_scalping(d15, '15m')
        df_1h = calc_indicators_scalping(d1h, '1h')
        ensemble, scaler = train_mtf_ensemble(df_5m, df_15m, df_1h)
        return ensemble, scaler, df_5m, df_15m, df_1h
    return None, None, None, None, None

# --- PHASE 3: FRONTEND INIT ---

st.set_page_config(page_title="ALADDIN MTF Scalping", page_icon="âš¡", layout="wide")

# INITIALIZE MT4 LINK IN SESSION STATE (ONCE)
if 'mt4_link' not in st.session_state:
    st.session_state.mt4_link = MT4Receiver()
    st.session_state.mt4_link.start()
    st.toast("Neural Link Initialized - Listening on Port 5555", icon="âš¡")

# UI STYLES
st.markdown("""

    * { font-family: 'Inter', sans-serif; }
    .main .block-container { padding: 1rem; max-width: 1700px; }
    h1 { color: #1a365d; font-size: 2.3rem !important; margin-bottom: 0.3rem !important; }
    .stMetric { background: #f7fafc; padding: 0.7rem; border-radius: 8px; border: 1px solid #e2e8f0; }
    .trade-card { padding: 1rem; border-radius: 8px; margin: 0.5rem 0; color: #1a202c; }
    .long { background: linear-gradient(to right, #d1fae5, #a7f3d0); border-left: 5px solid #059669; }
    .short { background: linear-gradient(to right, #fee2e2, #fecaca); border-left: 5px solid #dc2626; }

""", unsafe_allow_html=True)

st.title("âš¡ ALADDIN MTF CORE")

# SIDEBAR CONTROLS
with st.sidebar:
    st.header("Control Panel")
    symbol = st.selectbox("Asset Class", list(ASSETS.keys()), format_func=lambda x: ASSETS[x])
    live_mode = st.toggle("âš¡ LIVE TICK STREAM", value=True)
    if live_mode:
        st.caption("Refreshing every 1s...")
        time.sleep(1)
        st.rerun()

# MAIN LOGIC
key = f"mtf_{symbol}"
# Always try to load data if not present
if key not in st.session_state or st.button("ðŸ”„ Force Retrain"):
    with st.spinner("Calibrating Neural Net..."):
        ensemble, scaler, df_5m, df_15m, df_1h = train_mtf_system(symbol)
        if ensemble:
            mtf_signal, p5, p15, p1h = find_mtf_patterns(df_5m, df_15m, df_1h)
            st.session_state[key] = {
                'ensemble': ensemble, 'scaler': scaler,
                'df_5m': df_5m, 'df_15m': df_15m, 'df_1h': df_1h,
                'mtf_signal': mtf_signal
            }

if key in st.session_state:
    state = st.session_state[key]
    live_data = get_live_data(symbol)
    
    # 1. LIVE TELEMETRY ROW
    st.markdown(f"### ðŸ“¡ Telemetry: {live_data['source']}")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Live Price", f"${live_data['price']:.2f}")
    c2.metric("24h High", f"${live_data['high']:.2f}")
    c3.metric("24h Low", f"${live_data['low']:.2f}")
    
    align = state['mtf_signal']['alignment']
    c4.metric("MTF Alignment", align, delta="STRONG" if align=="STRONG" else "-WEAK", delta_color="normal")
    
    st.divider()
    
    # 2. AI PREDICTIONS
    trades = generate_scalping_trades(state['ensemble'], state['scaler'], state['df_5m'], state['df_15m'], state['df_1h'], state['mtf_signal'], live_data['price'])
    
    st.markdown("### ðŸ§  Neural Output")
    col_l, col_r = st.columns([2, 1])
    
    with col_l:
        for _, t in trades.iterrows():
            direction_class = "long" if t['Direction'] == "LONG" else "short"
            st.markdown(f"""
            
                
                    {t['Strategy']} â€¢ {t['Direction']}
                    {t['Probability']}%
                
                
                    ENTRY{t['Entry']}
                    STOP{t['SL']}
                    TARGET{t['TP']}
                    R/R{t['RR']}x
                
            
            """, unsafe_allow_html=True)

    with col_r:
        st.info("System Status: ONLINE")
        if align == "STRONG":
            st.success("Configuration: OPTIMAL")
        else:
            st.warning("Configuration: SUB-OPTIMAL")
        st.write(f"Last Update: {datetime.datetime.now().strftime('%H:%M:%S')}")
